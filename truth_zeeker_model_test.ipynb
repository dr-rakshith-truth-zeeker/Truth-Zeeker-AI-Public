{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cck-eJKJmM7G"
      },
      "outputs": [],
      "source": [
        "# Install required packages (run in Colab cell)\n",
        "!pip install -q huggingface_hub joblib pandas scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import joblib, json, os\n",
        "\n",
        "repo_id = \"dr-rakshith-truth-zeeker/truth-zeeker-ai-demo\"   # <-- confirm this\n",
        "model_filename = \"model_20251020.joblib\"                    # <-- confirm this\n",
        "\n",
        "print(\"Downloading HF model...\")\n",
        "hf_path = hf_hub_download(repo_id=repo_id, filename=model_filename, repo_type=\"model\")\n",
        "print(\"Downloaded to:\", hf_path)\n",
        "\n",
        "# Inspect\n",
        "obj = joblib.load(hf_path)\n",
        "print(\"\\n--- Hugging Face model info ---\")\n",
        "if isinstance(obj, dict):\n",
        "    print(\"type: dict\")\n",
        "    print(\"keys:\", list(obj.keys()))\n",
        "    print(\"features:\", obj.get(\"features\"))\n",
        "    print(\"has pipeline:\", isinstance(obj.get(\"pipeline\"), object) and obj.get(\"pipeline\") is not None)\n",
        "else:\n",
        "    print(\"Loaded object type:\", type(obj))\n",
        "    # if it's a sklearn pipeline directly\n",
        "    try:\n",
        "        print(\"If sklearn pipeline, get feature_names attribute (if present):\", getattr(obj, \"feature_names_in_\", None))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "# Keep the model/pipeline in memory for next cells:\n",
        "if isinstance(obj, dict) and \"pipeline\" in obj:\n",
        "    pipeline = obj[\"pipeline\"]\n",
        "    features = obj[\"features\"]\n",
        "elif hasattr(obj, \"predict\"):\n",
        "    pipeline = obj\n",
        "    features = None\n",
        "else:\n",
        "    raise RuntimeError(\"Model structure unexpected - let me know the printed output above.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbv7sS2vnNWG",
        "outputId": "cf4f8e13-af64-47ee-d7eb-f967451d4513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading HF model...\n",
            "Downloaded to: /root/.cache/huggingface/hub/models--dr-rakshith-truth-zeeker--truth-zeeker-ai-demo/snapshots/9d56c1ead5c64f2024c9dd59a06ca939e8c2a986/model_20251020.joblib\n",
            "\n",
            "--- Hugging Face model info ---\n",
            "type: dict\n",
            "keys: ['pipeline', 'features']\n",
            "features: ['conn_count', 'total_orig_bytes', 'total_resp_bytes', 'avg_duration', 'anomaly_score']\n",
            "has pipeline: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fallback: download CSV from HF and print simple text output (no JS interactive display)\n",
        "import pandas as pd\n",
        "from huggingface_hub import hf_hub_download\n",
        "import os\n",
        "\n",
        "repo_id = \"dr-rakshith-truth-zeeker/truth-zeeker-ai-demo\"\n",
        "csv_name = \"zeek_features_for_training_pseudo.csv\"\n",
        "\n",
        "# If the repo/file is private you must pass the token (set it below or in Colab secrets)\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\", None)   # set this env var in Colab if needed\n",
        "\n",
        "try:\n",
        "    if HF_TOKEN:\n",
        "        csv_path = hf_hub_download(repo_id=repo_id, filename=csv_name, repo_type=\"model\",\n",
        "                                   use_auth_token=HF_TOKEN)\n",
        "    else:\n",
        "        csv_path = hf_hub_download(repo_id=repo_id, filename=csv_name, repo_type=\"model\")\n",
        "    print(\"‚úÖ Downloaded CSV path:\", csv_path)\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Could not fetch CSV from HF: {e}\")\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Loaded shape:\", df.shape)\n",
        "print(\"\\nFirst 10 rows (text):\\n\")\n",
        "print(df.head(10).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhApSGf9t6wK",
        "outputId": "dc0b9871-0e42-4d61-c85b-b333904f37fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Downloaded CSV path: /root/.cache/huggingface/hub/models--dr-rakshith-truth-zeeker--truth-zeeker-ai-demo/snapshots/c1084d6ef2317cf7e4b5762654e7eb965f4afedf/zeek_features_for_training_pseudo.csv\n",
            "Loaded shape: (16, 9)\n",
            "\n",
            "First 10 rows (text):\n",
            "\n",
            " src_ip  conn_count  total_orig_bytes  total_resp_bytes  unique_dst_ports  avg_duration  total_orig_pkts  total_resp_pkts  anomaly_score\n",
            " host_1           1               0.0               0.0                 1      0.000000                1                0      -0.394479\n",
            " host_2           1               0.0               0.0                 1      0.000000                1                0      -0.394479\n",
            " host_3           1             150.0               0.0                 1      1.502042                3                0      -0.128259\n",
            " host_4           1               0.0               0.0                 1      0.000000                1                0      -0.394479\n",
            " host_5           1               0.0               0.0                 1      0.000000                1                0      -0.394479\n",
            " host_6           1               0.0               0.0                 1      0.000000                1                0      -0.394479\n",
            " host_7           1               0.0               0.0                 1      0.000000                1                0      -0.394479\n",
            " host_8           1           56780.0            6944.0                 1      4.074150               96               43      -0.015407\n",
            " host_9           2            8236.0           17704.0                 2      4.170239               24               32       0.006603\n",
            "host_10           1               0.0               0.0                 1      0.000000                1                0      -0.394479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# --- Config ---\n",
        "repo_id = \"dr-rakshith-truth-zeeker/truth-zeeker-ai-demo\"\n",
        "model_filename = \"model_20251020.joblib\"   # the HF model you uploaded earlier\n",
        "HF_TOKEN = os.environ.get(\"HF_TOKEN\", None)\n",
        "\n",
        "# --- Download model from HF ---\n",
        "try:\n",
        "    model_path = hf_hub_download(\n",
        "        repo_id=repo_id,\n",
        "        filename=model_filename,\n",
        "        repo_type=\"model\",\n",
        "        use_auth_token=HF_TOKEN\n",
        "    )\n",
        "    print(f\"‚úÖ Model downloaded from HF: {model_path}\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"‚ùå Could not download model: {e}\")\n",
        "\n",
        "# --- Load model ---\n",
        "model = joblib.load(model_path)\n",
        "print(f\"\\nLoaded model type: {type(model)}\")\n",
        "\n",
        "if isinstance(model, dict):\n",
        "    pipeline = model.get(\"pipeline\")\n",
        "    features = model.get(\"features\")\n",
        "else:\n",
        "    pipeline = model\n",
        "    features = None\n",
        "\n",
        "print(f\"Model features: {features}\")\n",
        "\n",
        "# --- Ensure required columns exist ---\n",
        "for f in features:\n",
        "    if f not in df.columns:\n",
        "        print(f\"‚ö†Ô∏è Missing feature column in CSV: {f}\")\n",
        "        df[f] = 0  # filler if needed\n",
        "\n",
        "# --- Run inference ---\n",
        "if pipeline:\n",
        "    preds = pipeline.predict(df[features])\n",
        "    df[\"anomaly_flag\"] = preds\n",
        "    print(\"\\n‚úÖ Inference complete. Sample output:\")\n",
        "    print(df.head(10).to_string(index=False))\n",
        "else:\n",
        "    print(\"‚ùå No valid pipeline found in model.\")\n",
        "\n",
        "# --- Save output CSV ---\n",
        "out_path = \"/content/zeek_inference_output.csv\"\n",
        "df.to_csv(out_path, index=False)\n",
        "print(f\"\\nüìÅ Saved inference results to: {out_path}\")\n"
      ],
      "metadata": {
        "id": "1n-JB2Pwv7R1",
        "outputId": "fdc8baef-e91e-4b0e-98d6-4d7968a5ec53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model downloaded from HF: /root/.cache/huggingface/hub/models--dr-rakshith-truth-zeeker--truth-zeeker-ai-demo/snapshots/c1084d6ef2317cf7e4b5762654e7eb965f4afedf/model_20251020.joblib\n",
            "\n",
            "Loaded model type: <class 'dict'>\n",
            "Model features: ['conn_count', 'total_orig_bytes', 'total_resp_bytes', 'avg_duration', 'anomaly_score']\n",
            "\n",
            "‚úÖ Inference complete. Sample output:\n",
            " src_ip  conn_count  total_orig_bytes  total_resp_bytes  unique_dst_ports  avg_duration  total_orig_pkts  total_resp_pkts  anomaly_score  anomaly_flag\n",
            " host_1           1               0.0               0.0                 1      0.000000                1                0      -0.394479             1\n",
            " host_2           1               0.0               0.0                 1      0.000000                1                0      -0.394479             1\n",
            " host_3           1             150.0               0.0                 1      1.502042                3                0      -0.128259             1\n",
            " host_4           1               0.0               0.0                 1      0.000000                1                0      -0.394479             1\n",
            " host_5           1               0.0               0.0                 1      0.000000                1                0      -0.394479             1\n",
            " host_6           1               0.0               0.0                 1      0.000000                1                0      -0.394479             1\n",
            " host_7           1               0.0               0.0                 1      0.000000                1                0      -0.394479             1\n",
            " host_8           1           56780.0            6944.0                 1      4.074150               96               43      -0.015407             1\n",
            " host_9           2            8236.0           17704.0                 2      4.170239               24               32       0.006603            -1\n",
            "host_10           1               0.0               0.0                 1      0.000000                1                0      -0.394479             1\n",
            "\n",
            "üìÅ Saved inference results to: /content/zeek_inference_output.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator ExtraTreeRegressor from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator IsolationForest from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.7.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a horizontal bar chart (JS-free) and save to file\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load results (from your previous cell)\n",
        "df = pd.read_csv(\"/content/zeek_inference_output.csv\")\n",
        "\n",
        "# Decide how to rank anomalies:\n",
        "# - If your model gives an 'anomaly_score' where larger means more anomalous:\n",
        "#     sort by 'anomaly_score' descending\n",
        "# - If the pipeline uses IsolationForest (-1 == anomaly), use anomaly_flag == -1\n",
        "# Here we'll pick top rows by anomaly_score (change if needed).\n",
        "if \"anomaly_score\" in df.columns:\n",
        "    top = df.sort_values(by=\"anomaly_score\", ascending=False).head(10)\n",
        "else:\n",
        "    top = df[df[\"anomaly_flag\"] == -1].head(10) if \"anomaly_flag\" in df.columns else df.head(10)\n",
        "\n",
        "# pick label for y-axis if available (hostnames) else use index\n",
        "if \"src_ip\" in top.columns:\n",
        "    labels = top[\"src_ip\"].astype(str)\n",
        "elif \"host\" in top.columns:\n",
        "    labels = top[\"host\"].astype(str)\n",
        "else:\n",
        "    labels = top.index.astype(str)\n",
        "\n",
        "scores = top[\"anomaly_score\"] if \"anomaly_score\" in top.columns else top[\"anomaly_flag\"]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.barh(labels, scores)\n",
        "plt.xlabel(\"Anomaly score (higher = more anomalous)\")\n",
        "plt.title(\"Top anomalous source hosts (example)\")\n",
        "plt.gca().invert_yaxis()  # biggest at top\n",
        "plt.tight_layout()\n",
        "\n",
        "out_png = \"/content/top_anomalies.png\"\n",
        "plt.savefig(out_png)\n",
        "print(f\"Saved chart to: {out_png}\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV_ZRxl6xOjH",
        "outputId": "086cd378-0e6f-48ca-b979-c8bcc6cfc0d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved chart to: /content/top_anomalies.png\n"
          ]
        }
      ]
    }
  ]
}